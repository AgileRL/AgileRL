---
# Define initial hyperparameters
INIT_HP:
    ENV_NAME: pettingzoo.mpe.simple_speaker_listener_v4 # pettingzoo.butterfly.knights_archers_zombies_v10 #  # Gym environment name
    ALGO: IPPO                                          # Algorithm
    # Swap image channels dimension from last to first [H, W, C] -> [C, H, W]
    CHANNELS_LAST: false
    NUM_ENVS: 16               # No. parallel environments for training
    BATCH_SIZE: 128            # Batch size
    LR: 0.0001                 # Learning rate
    LEARN_STEP: 2048           # Learning frequency
    MAX_STEPS: 2_000_000       # Max no. steps
    TARGET_SCORE:              # Early training stop at avg score of last 100 episodes
    GAMMA: 0.99                # Discount factor
    GAE_LAMBDA: 0.95           # Lambda for general advantage estimation
    ACTION_STD_INIT: 0.0       # Initial action standard deviation
    CLIP_COEF: 0.2             # Surrogate clipping coefficient
    ENT_COEF: 0.05             # Entropy coefficient
    VF_COEF: 0.5               # Value function coefficient
    MAX_GRAD_NORM: 0.5         # Maximum norm for gradient clipping
    TARGET_KL:                 # Target KL divergence threshold
    UPDATE_EPOCHS: 4           # Number of policy update epochs
    TOURN_SIZE: 2              # Tournament size
    ELITISM: true              # Elitism in tournament selection
    POP_SIZE: 4                # Population size
    EVO_STEPS: 10_000          # Evolution frequency
    EVAL_STEPS:                # Evaluation steps
    EVAL_LOOP: 1               # Evaluation episodes
    WANDB: false                # Log with Weights and Biases
    TORCH_COMPILE: default

MUTATION_PARAMS:
    NO_MUT: 0.4                            # No mutation
    ARCH_MUT: 0.4                          # Architecture mutation
    NEW_LAYER: 0.2                         # New layer mutation
    PARAMS_MUT: 0.2                        # Network parameters mutation
    ACT_MUT: 0.0                           # Activation layer mutation
    RL_HP_MUT: 0.35                        # Learning HP mutation
    # Learning HPs to choose from
    RL_HP_SELECTION: [lr, batch_size, learn_step]
    MUT_SD: 0.1                            # Mutation strength
    RAND_SEED: 42                          # Random seed
    MIN_LR: 0.000001                       # Define max and min limits for mutating RL hyperparams
    MAX_LR: 0.01
    MIN_BATCH_SIZE: 8
    MAX_BATCH_SIZE: 1024
    MIN_LEARN_STEP: 256
    MAX_LEARN_STEP: 8192
    MIN_ENT_COEF: 0.001
    MAX_ENT_COEF: 0.1

NET_CONFIG:
    latent_dim: 64

    encoder_config:
        hidden_size: [64]
        activation: ReLU
        min_mlp_nodes: 32
        max_mlp_nodes: 500
        layer_norm: true
        # channel_size: [32, 16]
        # kernel_size: [3, 3]
        # stride_size: [2, 2]
        # activation: ReLU

    head_config:
        hidden_size: [64]
        activation: ReLU
        output_activation:
        min_hidden_layers: 1
        max_hidden_layers: 3
        min_mlp_nodes: 32
        max_mlp_nodes: 256
        output_vanish: false
        layer_norm: true

DISTRIBUTED_TRAINING: false
